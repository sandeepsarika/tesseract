import pytesseract
import cv2
import requests
from bs4 import BeautifulSoup
from transformers import pipeline
from newspaper import Article
import tweepy

# SETUP: Huggingface Model (Pretrained)
classifier = pipeline("text-classification", model="mrm8488/bert-tiny-finetuned-fake-news-detection")

# SETUP: Twitter (X) API (you need your own credentials)
TWITTER_BEARER_TOKEN = "YOUR_TWITTER_BEARER_TOKEN"
client = tweepy.Client(bearer_token=TWITTER_BEARER_TOKEN)

# SETUP: Tesseract path (for Windows users)
# pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

def detect_fake_news(text):
    result = classifier(text)[0]
    return f"Prediction: {result['label']} (Confidence: {result['score']:.2f})"

def extract_text_from_image(image_path):
    image = cv2.imread(image_path)
    return pytesseract.image_to_string(image)

def search_news_articles(query):
    print("\nSearching News Sources...")
    url = f"https://www.google.com/search?q={query}+site:cnn.com+OR+site:bbc.com+OR+site:reuters.com"
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    results = []
    for g in soup.find_all('div', class_='BNeawe vvjwJb AP7Wnd')[:5]:
        results.append(g.get_text())
    return results if results else ["No relevant news found."]

def search_x_posts(query):
    print("\nSearching X (Twitter)...")
    tweets = client.search_recent_tweets(query=query, max_results=5)
    return [tweet.text for tweet in tweets.data] if tweets.data else ["No relevant tweets found."]

def process_input(input_data, is_image=False):
    if is_image:
        text = extract_text_from_image(input_data)
        print(f"\nExtracted Text from Image:\n{text}")
    else:
        text = input_data
    
    prediction = detect_fake_news(text)
    print(f"\nFake News Detection:\n{prediction}")
    
    news_results = search_news_articles(text[:100])
    print("\nNews Articles:")
    for i, item in enumerate(news_results, 1):
        print(f"{i}. {item}")

    tweets = search_x_posts(text[:100])
    print("\nRecent Tweets:")
    for i, tweet in enumerate(tweets, 1):
        print(f"{i}. {tweet}")
